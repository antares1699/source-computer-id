{"title":"Bagaimana cara memeriksa file duplikat?","draft":false,"url":"/bagaimana-cara-memeriksa-file-duplikat-0sphf5ia","votes":"4","answers_count":"3","categories":["Komputer"],"tags":["linux"],"snippet":"Saya memiliki hard drive eksternal tempat saya telah membuat cadangan file beberapa kali. Beberapa file diubah di antara backup, yang lainnya tidak. Beberapa mungkin telah diganti namanya. Sekarang saya kehabisan ruang, dan...","body":"<p> Saya memiliki hard drive eksternal tempat saya telah membuat cadangan file beberapa kali. Beberapa file diubah di antara backup, yang lainnya tidak. Beberapa mungkin telah diganti namanya. Sekarang saya kehabisan ruang, dan saya ingin membersihkan file duplikat. </p>\n\n<p> Ide saya adalah <code>md5sum</code> setiap file di drive, kemudian mencari duplikat, dan <code>diff</code> file yang relevan (untuk berjaga-jaga, haha). Apakah ini cara terbaik untuk melakukan ini? Apa sajakah metode lain untuk memeriksa file duplikat? </p>","source":"https://superuser.com/questions/122451/how-to-check-for-duplicate-files","author":"<span itemprop=\"name\">miorel</span>","replies":[{"reply":"Apakah Anda ingin menulis program untuk melakukan ini, atau menggunakan alat yang sudah ada?","author":"<a href=\"https://superuser.com/users/2484/michael-petrotta\" target=\"_blank\" rel=\"nofollow noopener\">Michael Petrotta</a>"},{"reply":"Saya sudah meretas ini bersama-sama di baris perintah menggunakan strategi yang dijelaskan, dan berhasil. Saya hanya ingin tahu apakah ada strategi lain.","author":"User"}],"answers":[{"answer":"<p> Menghitung hash MD5 untuk setiap file (disarankan dalam pertanyaan dan tautan dari jawaban) tampaknya merupakan cara yang cukup &quot;mahal&quot; untuk menyelesaikan masalah. Mengabaikan perhitungan sebenarnya dari setiap hash, hanya membaca setiap file akan benar-benar membuat banyak pekerjaan pada hard drive (sangat lambat). </p>\n\n<p> Saran saya untuk &quot;algoritme&quot; adalah sesuatu yang menghubungkan ini: </p>\n\n<ul>\n<li> Dapatkan panjang yang tepat dari setiap file di drive (atau direktori, atau apa pun). Ini seharusnya relatif murah, karena panjangnya kemungkinan besar akan disimpan di bagian indeks sistem file. </li>\n<li> Untuk setiap ukuran file unik dengan lebih dari satu file terkait, hitung MD5 masing-masing dan bandingkan nilai hash untuk menemukan duplikat. Meskipun sangat tidak mungkin, dua file dengan panjang yang sama dapat memiliki hash dengan nilai yang sama. Jika Anda tidak ingin mengambil risiko positif palsu, bandingkan file byte demi byte atau setelah perbandingan hash. </li>\n<li> Untuk setiap ukuran file unik lainnya, Anda tidak memiliki duplikat. </li>\n</ul>","votes":"3","source":"https://superuser.com/a/122454","author":"<a href=\"https://superuser.com/users/18730/j%c3%b8rn-schou-rode\" target=\"_blank\" rel=\"nofollow noopener\"><span itemprop=\"name\">J&#248;rn Schou-Rode</span></a>","replies":[{"reply":"Saya akan memeriksa ukuran, pada ukuran file dup, periksa dulu 512 byte (satu sektor), dan jika sama, maka komputer md5. Namun perlu diingat md5 membaca seluruh file untuk dihitung, jadi mengapa tidak hanya membandingkan biner seluruh file untuk memastikan (lagipula, md5 rusak)","author":"<a href=\"https://superuser.com/users/130931/cole-johnson\" target=\"_blank\" rel=\"nofollow noopener\">Cole Johnson</a>"},{"reply":"&quot;dua file dengan panjang yang sama&quot;: tidak, ini lebih umum: &quot;dua file&quot;: tabrakan md5 yang mungkin tidak memerlukan panjang input yang sama (hal yang sama berlaku untuk sha * dll).","author":"<a href=\"https://superuser.com/users/10674/akira\" target=\"_blank\" rel=\"nofollow noopener\">akira</a>"}]},{"answer":"<p> Jika md5 mengatakan itu file yang sama, Anda tidak memerlukan diff. Orang-orang telah memecahkan masalah ini beberapa kali sehingga Anda dapat melakukan apa yang mereka lakukan <a href=\"http://embraceubuntu.com/2005/10/08/find-duplicate-copies-of-files/\" rel=\"nofollow noopener\" target=\"_blank\"> melakukan </a> . </p>","votes":"2","source":"https://superuser.com/a/122452","author":"<a href=\"https://superuser.com/users/34914/tomislav-nakic-alfirevic\" target=\"_blank\" rel=\"nofollow noopener\"><span itemprop=\"name\">Tomislav Nakic-Alfirevic</span></a>","replies":[{"reply":"Uh, ya, Anda memang membutuhkan diff untuk memastikan keduanya sama. MD5 hanya mengeluarkan 128 bit, jadi jika file Anda lebih besar dari itu, itu pasti mungkin untuk menemukan dua file A dan B yang memiliki MD5 yang sama, tetapi tidak memiliki konten yang sama. Jika dua file memiliki MD5 yang berbeda, maka Anda tahu keduanya berbeda, tetapi sebaliknya tidak demikian - Anda harus membandingkan setiap byte file jika Anda ingin benar-benar yakin bahwa keduanya berbeda.","author":"User"},{"reply":"jadi jika file saya lebih besar dari 128 <i> sedikit </i> Saya harus melalui semua 100 <i> Megabyte </i> , sebagai contoh?? Kedengarannya tidak benar, karena inti dari hashing adalah melakukan hashing <i> seluruh </i> mengajukan. Meskipun ada duplikat yang terjadi saat menggunakan hash MD5, kemungkinan salah satu terjadi antara dua file tidak berbahaya yang dibuat pengguna sangat rendah. SHA 256 atau 512 lebih disukai sekarang.","author":"<a href=\"https://superuser.com/users/35868/mdmoore313\" target=\"_blank\" rel=\"nofollow noopener\">MDMoore313</a>"},{"reply":"@Michael Dengan hash 128-bit yang bagus, ada sekitar 10 ^ 40 kemungkinan nilai keluaran. Jika tumpang tindih dua nilai seperti itu adalah jenis risiko yang membuat Anda terjaga di malam hari ... yah, saya hanya akan mengatakan itu tidak membuat saya terjaga di malam hari. ;)","author":"<a href=\"https://superuser.com/users/34914/tomislav-nakic-alfirevic\" target=\"_blank\" rel=\"nofollow noopener\">Tomislav Nakic-Alfirevic</a>"}]},{"answer":"<p> Lihat disini: </p>\n\n<p><a href=\"http://www.codeproject.com/KB/files/DuplicateFinder.aspx\" rel=\"nofollow noopener\" target=\"_blank\"> Pencari File Duplikat </a></p>\n\n<p><a href=\"http://msdn.microsoft.com/en-us/library/bb546133.aspx\" rel=\"nofollow noopener\" target=\"_blank\"> Cara: Query for Duplicate Files in a Directory Tree (LINQ) </a></p>","votes":"1","source":"https://superuser.com/a/122453","author":"<a href=\"https://superuser.com/users/33242/leniel-maccaferri\" target=\"_blank\" rel=\"nofollow noopener\"><span itemprop=\"name\">Leniel Maccaferri</span></a>","replies":[]}]}
